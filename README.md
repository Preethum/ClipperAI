# ğŸ¬ ClipperAI

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-active-brightgreen.svg)](https://github.com/yourusername/ClipperAI)
[![Contributors](https://img.shields.io/badge/contributors-welcome-orange.svg)](CONTRIBUTING.md)

> ğŸ¤– **AI-Powered Video Clipping System** - Automatically extract viral clips from long-form videos using advanced AI analysis and multi-agent processing.

## âœ¨ Features

- ğŸ§  **Multi-Agent AI Analysis** - Scout + Editor pipeline for intelligent clip selection
- ğŸ¯ **Smart Content Detection** - Identifies viral moments, hooks, and payoff points
- ğŸ“± **Vertical Format Optimization** - Automatic 9:16 cropping for social media
- ğŸ“ **Dynamic Subtitle Generation** - AI-powered transcription with styled overlays
- ğŸ”§ **Modular Architecture** - Extensible pipeline with customizable scenarios
- âš¡ **High-Performance Processing** - GPU-accelerated transcription and analysis
- ğŸ¨ **Template System** - Customizable subtitle templates and styling
- ğŸ“Š **Quality Scoring** - Hybrid virality metrics for optimal clip selection

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- NVIDIA GPU (recommended for faster processing)
- FFmpeg (included in `/bin` directory)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/ClipperAI.git
cd ClipperAI

# Create virtual environment
python -m venv clipper-venv
source clipper-venv/bin/activate  # On Windows: clipper-venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```bash
# Process a video with default settings
python src/scenarios/podcast.py --input "your_video.mp4" --output "clips" --clips 10

# Process MrBeast-style content
python src/scenarios/podcast.py --input "mrbeast_video.mp4" --output "viral_clips" --clips 15

# Process podcast content
python src/scenarios/podcast.py --input "podcast_episode.mp4" --output "podcast_clips" --clips 20
```

## ğŸ“ Project Structure

```
ClipperAI/
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“‚ modules/              # Core processing modules
â”‚   â”‚   â”œâ”€â”€ ğŸ ClipperM.py       # AI-powered clip extraction
â”‚   â”‚   â”œâ”€â”€ âœ‚ï¸ CropperM.py       # Smart video cropping
â”‚   â”‚   â””â”€â”€ ğŸ“ SubsM.py          # Subtitle generation
â”‚   â”œâ”€â”€ ğŸ“‚ scenarios/           # Video processing scenarios
â”‚   â”‚   â””â”€â”€ ğŸ™ï¸ podcast.py        # Podcast processing pipeline
â”‚   â””â”€â”€ ğŸ“‚ utils/
â”‚       â””â”€â”€ ğŸ› ï¸ path_utils.py     # Path resolution utilities
â”œâ”€â”€ ğŸ“‚ bin/                      # External binaries
â”‚   â”œâ”€â”€ ğŸ¬ ffmpeg.exe
â”‚   â”œâ”€â”€ ğŸ® ffplay.exe
â”‚   â””â”€â”€ ğŸ” ffprobe.exe
â”œâ”€â”€ ğŸ“‚ templates/               # Subtitle templates
â”œâ”€â”€ ğŸ“‚ output/                  # Generated clips
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“– README.md
â””â”€â”€ ğŸš« .gitignore
```

## ğŸ¯ Processing Pipeline

### 1. **Clipper Module** - AI Analysis
- **Transcription**: Whisper-based speech-to-text
- **OCR Analysis**: Visual content extraction
- **Semantic Chapters**: Content segmentation
- **Multi-Agent Selection**: Scout + Editor pipeline
- **Virality Scoring**: Hybrid metrics (narrative + visual + audio)

### 2. **Cropper Module** - Format Optimization
- **Smart Cropping**: Face detection and tracking
- **Aspect Ratio**: 9:16 vertical format
- **Quality Control**: Multiple encoding presets
- **Scene Analysis**: Optimal framing selection

### 3. **Subs Module** - Subtitle Generation
- **Dynamic Styling**: Template-based rendering
- **Positioning**: Smart vertical alignment
- **Font Scaling**: Responsive text sizing
- **Template System**: Customizable designs

## âš™ï¸ Configuration

### Default Settings

```python
{
    "modules": {
        "clipper": {
            "min_clip_duration": 45.0,      # Minimum clip length (seconds)
            "max_clip_duration": 90.0,      # Maximum clip length (seconds)
            "max_total_clips": 10,           # Maximum number of clips
            "scout_model": "deepseek-r1-distill-qwen-32b",
            "editor_model": "google/gemma-3-27b",
            "lm_studio_url": "http://localhost:1234/v1"
        },
        "cropper": {
            "ratio": "9:16",                 # Target aspect ratio
            "quality": "balanced",           # Encoding quality
            "encoder": "auto"                # Auto-select best encoder
        },
        "subs": {
            "template": "hype",              # Subtitle template
            "vertical_align_offset": 0.70,   # Vertical positioning
            "max_width_ratio": 0.9,          # Maximum text width
            "max_lines": 1                   # Maximum subtitle lines
        }
    }
}
```

### Command Line Options

```bash
python src/scenarios/podcast.py [OPTIONS]

Required:
  --input TEXT        Input video file path
  --output TEXT       Output directory path

Optional:
  --clips INTEGER     Maximum number of clips (default: 10)
  --config TEXT       Path to JSON configuration file
  --min-duration FLOAT Minimum clip duration (default: 45.0)
  --max-duration FLOAT Maximum clip duration (default: 90.0)
```

## ğŸ“Š Output Structure

```
output/
â”œâ”€â”€ ğŸ“‚ 01_clips/              # Clipper output
â”‚   â”œâ”€â”€ ğŸ¬ viral_clip_1.mp4
â”‚   â”œâ”€â”€ ğŸ¬ viral_clip_2.mp4
â”‚   â””â”€â”€ ğŸ“Š clips_metadata.json
â”œâ”€â”€ ğŸ“‚ 02_cropped/            # Cropper output
â”‚   â”œâ”€â”€ ğŸ“± viral_clip_1.mp4
â”‚   â””â”€â”€ ğŸ“± viral_clip_2.mp4
â””â”€â”€ ğŸ“‚ 03_final/              # Final output with subtitles
    â”œâ”€â”€ ğŸ¥ viral_clip_1.mp4
    â””â”€â”€ ğŸ¥ viral_clip_2.mp4
```

## ğŸ¨ Subtitle Templates

### Available Templates
- **hype** - High-energy, bold styling
- **default** - Clean, minimal design
- **custom** - Your custom templates

### Creating Custom Templates

1. Navigate to `/templates/` directory
2. Create your template folder
3. Add subtitle configuration files
4. Reference in config: `"template": "your_template_name"`

## ğŸ§  AI Models

### Supported Models
- **Scout Model**: `deepseek-r1-distill-qwen-32b` - Content analysis and filtering
- **Editor Model**: `google/gemma-3-27b` - Creative selection and refinement
- **Transcription**: Whisper (small, medium, large models)
- **OCR**: EasyOCR with GPU acceleration

### Model Configuration
```python
# LM Studio integration
"lm_studio_url": "http://localhost:1234/v1"

# Whisper settings
whisper_model = "small"  # Options: tiny, base, small, medium, large
device = "cuda"           # GPU acceleration
compute_type = "float16"  # Precision optimization
```

## ğŸ”§ Advanced Usage

### Custom Configuration File

Create a JSON config file:

```json
{
    "input_video": "custom_video.mp4",
    "base_output_dir": "custom_output",
    "modules": {
        "clipper": {
            "max_total_clips": 25,
            "min_clip_duration": 30.0,
            "max_clip_duration": 120.0
        },
        "cropper": {
            "ratio": "16:9",
            "quality": "high"
        },
        "subs": {
            "template": "custom_template",
            "max_lines": 2
        }
    }
}
```

Run with custom config:
```bash
python src/scenarios/podcast.py --config custom_config.json
```

### Batch Processing

```bash
# Process multiple videos
for video in *.mp4; do
    python src/scenarios/podcast.py --input "$video" --output "clips_$(basename "$video" .mp4)" --clips 15
done
```

## ğŸ› ï¸ Development

### Adding New Modules

1. Create module in `src/modules/`
2. Implement required interface
3. Register in scenario pipeline
4. Add configuration options

### Adding New Scenarios

1. Create scenario file in `src/scenarios/`
2. Define processing pipeline
3. Configure module settings
4. Add command-line interface

### Testing

```bash
# Run tests
python -m pytest tests/

# Test with sample video
python src/scenarios/podcast.py --input "sample_video.mp4" --output "test_output" --clips 3
```

## ğŸ› Troubleshooting

### Common Issues

**âŒ Bin directory not found**
```bash
# Ensure FFmpeg binaries are in /bin directory
ls bin/
# Should show: ffmpeg.exe, ffplay.exe, ffprobe.exe
```

**âŒ CUDA out of memory**
```python
# Reduce model size in ClipperM.py
whisper_model = "base"  # Use smaller model
```

**âŒ LM Studio connection failed**
```bash
# Ensure LM Studio is running on port 1234
# Check model availability in LM Studio
```

**âŒ Template not found**
```bash
# Verify template exists in templates/ directory
ls templates/
```

### Debug Mode

Enable verbose logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ˆ Performance Optimization

### GPU Requirements
- **VRAM**: 8GB+ recommended for large models
- **CUDA**: 11.0+ for optimal performance
- **Memory**: 16GB+ system RAM

### Speed Tips
- Use GPU acceleration (`device="cuda"`)
- Choose appropriate model sizes
- Optimize clip duration ranges
- Use SSD for video I/O

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone your fork
git clone https://github.com/yourusername/ClipperAI.git
cd ClipperAI

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI** - Whisper transcription model
- **EasyOCR** - Text extraction from video frames
- **LM Studio** - Local LLM inference
- **MoviePy** - Video processing
- **FFmpeg** - Media encoding/decoding

## ğŸ“ Support

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/yourusername/ClipperAI/issues)
- ğŸ’¡ **Feature Requests**: [GitHub Discussions](https://github.com/yourusername/ClipperAI/discussions)
- ğŸ“§ **Email**: your-email@example.com

---

<div align="center">

**ğŸ¬ Built with â¤ï¸ for content creators and social media managers**

[â­ Star this repo](https://github.com/yourusername/ClipperAI) â€¢ [ğŸ´ Fork](https://github.com/yourusername/ClipperAI/fork) â€¢ [ğŸ“– Documentation](https://github.com/yourusername/ClipperAI/wiki)

</div>
